{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9480b92a",
   "metadata": {},
   "source": [
    "# Strict Exogeneity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61c987d3",
   "metadata": {},
   "source": [
    "This is one of the most important assumptions of OLS which makes the OLS estimate **BLUE**. Strict exogeneity means that each error term is uncorrelated with the entire design matrix **X**.\n",
    "\n",
    "$$ \\mathbb{E}[\\epsilon_n | \\text{X}] = 0, \\quad n \\in \\{1,\\dots,N\\} $$\n",
    "\n",
    "or\n",
    "\n",
    "$$ \\mathbb{E}[\\mathbb{\\epsilon} | \\text{X}] = 0 $$\n",
    "\n",
    "If $ \\mathbb{E}[\\mathbb{\\epsilon} | \\text{X}] = 0 $, then\n",
    "\n",
    "- $ \\mathbb{E}[\\mathbb{\\epsilon}] = 0 $ : The error has no internal structure\n",
    "- $ \\mathbb{E}[\\mathbb{\\epsilon}\\text{X}] = 0 $ : This rules out the possibility that **X** and error are correlated\n",
    "- $ \\mathbb{E}[\\mathbb{\\epsilon} | \\mathcal{f}(\\text{X})] = \\mathbb{E}[\\mathbb{\\epsilon}\\mathcal{f}(\\text{X})] = 0 $ : For some finite valued function $\\mathcal{f}$, $\\mathcal{f}(\\text{X})$ and error are correlated. This is particularly of interest, since with this assumption you may include $\\mathcal{f}(\\text{X})$, as a regressor and still have OLS providing you unbiased estimates. i.e OLS estimate will unbiased even for models like $y=\\beta_0 + \\beta_1 x_1 + \\beta_2 x_2 + \\beta_3 x_1^2 + \\beta_4 x_2^2 + \\beta_5 x_1x_2$\n",
    "- $ \\mathbb{E}[y | \\text{X}] = \\text{X}\\beta $ : $ \\mathbb{E}[y | \\text{X}] = \\mathbb{E}[\\text{X}\\beta + \\epsilon | \\text{X}] = \\text{X}\\beta + \\mathbb{E}[\\epsilon | \\text{X}] = \\text{X}\\beta + 0 = \\text{X}\\beta $\n",
    "\n",
    "Because of these, strict exogeneity implies:\n",
    "\n",
    "- There is no internal structure to the error.\n",
    "- There is no external structure to the error tied to the predictors.\n",
    "- OLS estimate will unbiased even for $\\mathcal{f}(\\text{X})$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68f6645f",
   "metadata": {},
   "source": [
    "## Why is this assumption broken?\n",
    "\n",
    "The violation of exogeneity is known as **endogeneity** and there are may come situations when the assumption of strict exogeneity is broken. This may happen in cases like\n",
    "\n",
    "### Omitted variable bias\n",
    "\n",
    "Suppose the true model is\n",
    "\n",
    "$$ y = \\beta_1 X + \\beta_2 W + \\epsilon $$\n",
    "\n",
    "But we omit **w**, and estimate\n",
    "\n",
    "$$ y = \\beta_1 X + u $$\n",
    "\n",
    "Now the error term, $u=\\beta_2 W + \\epsilon$ will contain **W** and for most of the practical situations **W** will be some what correlated to **X**. That means\n",
    "\n",
    "$$ \\mathbb{E}[u | \\text{X}] \\neq 0 $$\n",
    "\n",
    "### Simultaneity Bias\n",
    "\n",
    "This is when the both independent variable and target variable are simultaneously dependent on each other. There is no directionality of the dependence but we try to model in one direction.\n",
    "\n",
    "**Example:**\n",
    "\n",
    "Let say we are trying to model students score in an exam based on the study hours the student put in the preparation. For this the model will be\n",
    "\n",
    "$$ \\text{score} = \\beta_0 + \\beta_1 \\text{study_hours} + \\epsilon $$\n",
    "\n",
    "We know that there is monotonic relationship between exam score and the study hours. If the student study more hours its more likely to get high score. However, if the student expects the exam to be easy and get high score, the student may study for less hours. Therefore, there is a relationship between exam score and study hours both ways.\n",
    "\n",
    "$$ \\text{score} \\leftrightarrow \\text{study_hours} $$\n",
    "\n",
    "Because of the bi-directional dependence between independence, the error becomes correlated to the design matrix **X**.\n",
    "\n",
    "### Reverse Causality\n",
    "\n",
    "This is when we create a model in a reverse relationship. i.e we create a model\n",
    "\n",
    "$$ y = \\beta_0 + \\beta_1 x + \\epsilon $$\n",
    "\n",
    "but in reality, $ x \\sim y $ instead of $ y \\sim x $ as modeled. Because of this the error becomes correlated to the design matrix **X**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e25f98b5",
   "metadata": {},
   "source": [
    "## Consequence of Endogeneity\n",
    "\n",
    "Let us take a look at what happens when the assumption of strict exogeneity is broken\n",
    "\n",
    "### OLS Estimates Become Biased and Inconsistent\n",
    "\n",
    "We have seen in previous sections that the $\\hat\\beta$ can be represented in terms of $\\beta$ as\n",
    "\n",
    "$$ \\hat\\beta = \\beta + (\\text{X}^T\\text{X})^{-1}\\text{X}^T\\epsilon $$\n",
    "\n",
    "Taking expectation of both side conditioned on the design matrix, we get\n",
    "\n",
    "\\begin{align*}\n",
    "\\mathbb{E}[\\hat\\beta | \\text{X}] &= \\mathbb{E}[\\beta + (\\text{X}^T\\text{X})^{-1}\\text{X}^T\\epsilon | \\text{X}] \\\\\n",
    "                      &= \\beta +  \\mathbb{E}[(\\text{X}^T\\text{X})^{-1}\\text{X}^T\\epsilon | \\text{X}] \\\\\n",
    "                      &= \\beta +  (\\text{X}^T\\text{X})^{-1}\\text{X}^T\\mathbb{E}[\\epsilon | \\text{X}] \\\\\n",
    "\\end{align*}\n",
    "\n",
    "So now if strict exogeneity if broken i.e $\\mathbb{E}[\\epsilon | \\text{X}] \\neq 0$ then $\\mathbb{E}[\\hat\\beta | \\text{X}] \\neq \\beta$ and the estimate will be biased.\n",
    "\n",
    "### Inference Is Invalid\n",
    "\n",
    "Because the OLS estimator is biased:\n",
    "\n",
    "- Confidence intervals no longer cover the true $\\beta$ with the advertised probability\n",
    "- p-values are meaningless\n",
    "- Hypothesis testing becomes unreliable\n",
    "\n",
    "### Variance Estimates Are Wrong\n",
    "\n",
    "We have seen in previous section that the variance formula for OLS also assumes exogeneity is give by\n",
    "\n",
    "$$ \\mathbb{V}[\\hat\\beta] = \\sigma(\\text{X}^T\\text{X})^{-1} $$\n",
    "\n",
    "If errors correlate with predictors:\n",
    "\n",
    "- The residuals are “contaminated” with information about **X**\n",
    "- Standard error formulas become invalid\n",
    "- This leads to overconfident or misleading conclusions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aa43544",
   "metadata": {},
   "source": [
    "## How to address Endogeneity?\n",
    "\n",
    "There is no way we completely get rid of endogeneity but we there are ways which can reduce the affects of this violation.\n",
    "\n",
    "### Add more relevant variable\n",
    "\n",
    "We have seen earlier that endogeneity may arise due to omitted variables and the simplest way to overcome it is including additional independent variable that can restore the assumption.\n",
    "\n",
    "### Choosing correct model\n",
    "\n",
    "The simultaneity bias and the reverse causality can be addressed by carefully and correctly building the model. It may sometimes be difficult to completely avoid these biases but a deeper understanding of the domain, reformulation of the problem and selecting correct directionality of the relationship can be helpful.\n",
    "\n",
    "### Instrumental Variables\n",
    "\n",
    "One way to address endogeneity is to use instrument variables. In this approach, the problematic design matrix **X** is replaced with and instrument **Z** which is:\n",
    "- Correlated to **X**\n",
    "- Uncorrelated with the error, $\\epsilon$\n",
    "\n",
    "This is the idea behind **2SLS (Two Stage Least Squares)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fe06322",
   "metadata": {},
   "source": [
    "## Two Stage Least Squares (2SLS)\n",
    "\n",
    "You want to estimate:\n",
    "\n",
    "$$ y = \\beta_0 + \\beta_1\\text{X} + \\epsilon $$\n",
    "\n",
    "but **X** is endogenous i.e. $\\text{Cov}(\\text{X}, \\epsilon) \\neq 0$\n",
    "\n",
    "So we introduce an instrument **Z** such that\n",
    "\n",
    "- $\\text{Cov}(\\text{Z}, \\text{X}) \\neq 0$ : relevance\n",
    "- $\\text{Cov}(\\text{Z}, \\epsilon) = 0$ : exogeneity\n",
    "\n",
    "In 2SLS, we do not directly use our design matrix **X** for predicting the target variable. Instead the model is built in two stages.\n",
    "\n",
    "**Stage 1**: Regress endogenous variable **X** on instrument(s) **Z**\n",
    "\n",
    "$$ \\text{X} = \\pi_0 + \\pi_1\\text{Z} + u $$\n",
    "\n",
    "We get predicted values:\n",
    "\n",
    "$$ \\hat{\\text{X}} = \\pi_0 + \\pi_1\\text{Z} $$\n",
    "\n",
    "This $\\hat{\\text{X}}$ cleaned of endogeneity, since they come from **Z**, which is exogenous.\n",
    "\n",
    "**Stage 2**: Regress **y** on $\\hat{\\text{X}}$\n",
    "\n",
    "$$ \\text{y} = \\beta_0 + \\beta_1\\hat{\\text{X}} + v $$\n",
    "\n",
    "Here’s the key, The error term $v$ in this stage is not the same as the original structural error $\\epsilon$, but it still exists.\n",
    "\n",
    "Even though $\\hat{\\text{X}}$ is uncorrelated with $\\epsilon$, it cannot explain all variation in **y** because there are still other unobserved factors in **y**. So even after using $\\hat{\\text{X}}$, the second-stage regression has a residual that includes whatever is left of $\\epsilon$ plus any approximation error. But this residual is now uncorrelated with $\\hat{\\text{X}}$ because $\\hat{\\text{X}}$ comes from **Z** which is orthogonal to $\\epsilon$.\n",
    "\n",
    "\n",
    "In matrix form, the normal equation will be\n",
    "\n",
    "$$ \\hat{\\beta}_{\\text{2SLS}} = (\\text{X}^TP_z\\text{X})^{-1}\\text{X}^TP_zy $$\n",
    "\n",
    "where, \n",
    "- $P_z = \\text{Z}(\\text{Z}^T\\text{Z})^{-1}\\text{Z}^T$ is the projection matrix onto the column space of $\\text{Z}$\n",
    "- This projects both $\\text{X}$ and $y$ onto the space spanned by the instruments\n",
    "\n",
    "### Caveats\n",
    "\n",
    "Although, two stage least square can relax exogeneity assumption in OLS, the 2SLS estimator is not **BLUE**\n",
    "\n",
    "- **Is it unbiased?**\n",
    "\n",
    "Taking expectation of the 2SLS estimate\n",
    "\n",
    "\\begin{align*}\n",
    "    \\mathbb{E}[\\hat{\\beta}_{\\text{2SLS}}|\\text{X}] &= \\mathbb{E}[(\\text{X}^TP_z\\text{X})^{-1}\\text{X}^TP_zy|\\text{X}] \\\\\n",
    "                                          &= \\mathbb{E}[(\\text{X}^TP_z\\text{X})^{-1}\\text{X}^TP_z(\\text{X}\\beta + \\epsilon)|\\text{X}] \\\\\n",
    "                                          &= \\mathbb{E}[(\\text{X}^TP_z\\text{X})^{-1}(\\text{X}^TP_z\\text{X})\\beta + (\\text{X}^TP_z\\text{X})^{-1}\\text{X}^TP_z\\epsilon|\\text{X}] \\\\\n",
    "                                          &= \\beta + \\mathbb{E}[(\\text{X}^TP_z\\text{X})^{-1}\\text{X}^TP_z\\epsilon|\\text{X}] \\\\\n",
    "                                          &= \\beta + \\mathbb{E}[(\\text{X}^T\\text{Z}(\\text{Z}^T\\text{Z})^{-1}\\text{Z}^T\\text{X})^{-1}\\text{X}^T\\text{Z}(\\text{Z}^T\\text{Z})^{-1}\\text{Z}^T\\epsilon|\\text{X}] \\\\\n",
    "\\end{align*}\n",
    "\n",
    "Even though $\\mathbb{E}[\\text{Z}^T\\epsilon] = 0$ (Z and $\\epsilon$ are uncorrelated), because of the randomness involved in the second term, it cannot be zero. Hence, $\\hat{\\beta}_{\\text{2SLS}}$ is not unbiased.\n",
    "\n",
    "However, $\\hat{\\beta}_{\\text{2SLS}}$ is **consistent** (convergence in probability)\n",
    "\n",
    "$$ \\hat{\\beta}_{\\text{2SLS}} \\overset{P}{\\to} \\beta $$\n",
    "\n",
    "- **Minimum variance?**\n",
    "\n",
    "The 2SLS estimator generally has higher variance than OLS"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
